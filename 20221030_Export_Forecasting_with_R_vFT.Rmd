---
title: "Soybean Export Forecast with R"
author: "Felipe Tufaile, Vinicius de Camargo, Helena Funari, Rodrigo Zamengo"
date: "`r Sys.Date()`"
output: html_document
---

### Summary

This document aims to study the time series of soybean exports with the aid of the R language and packages available for time series analysis for the mentioned programming language. The study will focus only on the Midwest region of Brazil in order to diminish the impact of different seasonal patterns in the soybean production cycle in different regions of Brazil. The study will, therefore, cover the analysis of its components (trend, seasonality and noise), forecasting export volume for future months using time series models like **sarima** and **prophet**, the implementation of techniques for adjusting the time series as well as any other observation on the characteristics of the time series that might be relevant.


```{r configs, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, include = TRUE, message = FALSE)
```

### Loading libraries

```{r libraries}

## Set working directory
setwd("~/Insper/Commodity_Export_Forecast")

library(dplyr)
library(tidyverse)
library(ggthemes)
library(fpp3)
library(forecast)
library(gridExtra)
library(ggpubr)
library(tseries)
library(prophet)
```

### Defining Functions

The following codes aims to define some function that will help plotting graphs and analyzing the time series through this study.

```{r functions}

## Creating function for adding time series to ggplots
add_serie <- function(data, xdata, ydata, name, color, text_position, labels) {

  list(geom_line(data=data, aes(x=.data[[xdata]], y=.data[[ydata]], color=name), linetype="solid", alpha=0.8),
       geom_text(data=data, aes(x=.data[[xdata]], y=.data[[ydata]], label=.data[[labels]]),
                 colour = color,
                 size=2.5, 
                 vjust=ifelse(text_position=="Above", -1, 2), hjust=0.5))
}

## Defining custom x-labels for time series plot without lag
time_series_xlabels <- function(){
  scale_x_date(breaks=seq(from=as.Date("1997-01-01"), to=as.Date("2022-01-01"), by = "12 month"), 
               date_label = "%b\n%y", expand=expansion(mult = c(0.02, 0.02)))
}

## Defining custom themes
time_series_theme <- function(){
  theme_hc() +
  theme(plot.background = element_rect(fill = "white"),
        panel.background = element_rect(fill = "white"),
        panel.grid.major.y = element_line(colour = '#E6E7E8'),
        panel.grid.minor.y = element_line(colour = '#E6E7E8'),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        axis.line.y = element_line(colour = '#000000'),
        axis.line.x = element_line(colour = '#000000'),
        axis.text.y = element_text(colour = '#000000', size=8),
        axis.ticks.y = element_line(colour = '#000000'),
        axis.title.y = element_text(colour = '#000000', size=8),
        legend.position = "bottom",
        plot.title = element_text(colour = "#000000", size=14),
        plot.subtitle = element_text(colour = '#585858', size=12),
        text = element_text(colour = '#585858', size=9),
        axis.text = element_text(colour = '#585858', size=8))
}

## Function Time Series Cross Validation SARIMA
tswcv <- function(series, x, y, model, min.window.size, window.type=c("fixed", "variable")){
  
  ### --- Time Series Window Cross validation --- ###
  
  ## Defining the last datat point
  k <- dim(series)[1]-min.window.size
  
  ## Saving SARIMA parameters from the given model
  p <- model$arma[1]
  d <- model$arma[6]
  q <- model$arma[2]
  P <- model$arma[3]
  D <- model$arma[7]
  Q <- model$arma[4]
  s <- model$arma[5]
  lbd <- model$lambda
  
  ## Initializing the errors vector
  errors <- c()
  
  ## Initializing the windows.size vector
  windows.size <- c()
  
  for (i in 1:k){
    
    ## Defining end data position
    n <- i+min.window.size-1
    
    ## Checking the window type
    if(window.type == "fixed"){m <- i}
    if(window.type == "variable"){m <- 1}
    
    ## Defining the start point of the window time series
    series_sy <- year(series[m, which(names(series)==x)] %>% pull())
    series_sm <- month(series[m, which(names(series)==x)] %>% pull())
    
    ## Defining the end point of the window time series
    series_ey <- year(series[n, which(names(series)==x)] %>% pull())
    series_em <- month(series[n, which(names(series)==x)] %>% pull())
  
    ## Creating time series
    ts_series <- ts(data=series[m:n, which(names(series)==y)], # selecting serie
                    start=c(series_sy, series_sm), # start month
                    end=c(series_ey, series_em), # end month 
                    frequency=12) # frequency
    

    ## Building a model with the parameters above using the new training data
    new_model <- Arima(y=ts_series,order=c(p,d,q),seasonal=list(order=c(P,D,Q),period=s),method="ML",lambda=lbd)
    
    ## Forecasting the next datapoint
    pred <- forecast(new_model,h=1)
    
    ## Filtering the original value
    actual <- series[n+1, which(names(series)==y)] %>% pull()
    
    ## calculating squared errors
    error_sqr <- (pred$mean[1]-actual)^2
    
    ## Updating the errors vector
    errors <- c(errors, error_sqr)
    
    ## Calculating the window size
    windows.size <- c(windows.size, n-m+1)
  }
  
  ## Calculating mean squared errors
  rmse <- (sum(errors)/length(errors))^0.5
  
  return(list("rmse"=rmse, "errors_squared"=errors, "window_size"=windows.size))
  
}

## Function Time Series Cross Validation Prophet
tswcv_prophet <- function(series, x, y, min.window.size, window.type=c("fixed", "variable")){
  
  ### --- Time Series Window Cross validation for Prophet --- ###
  
  ## Defining the last datat point
  k <- dim(series)[1]-min.window.size
  
  ## Initializing the errors vector
  errors <- c()
  
  ## Initializing the windows.size vector
  windows.size <- c()
  
  for (i in 1:k){
    
    ## Defining end data position
    n <- i+min.window.size-1
    
    ## Checking the window type
    if(window.type == "fixed"){m <- i}
    if(window.type == "variable"){m <- 1}
    
    ## Defining the start point of the window time series
    series_sy <- year(series[m, which(names(series)==x)] %>% pull())
    series_sm <- month(series[m, which(names(series)==x)] %>% pull())
    
    ## Defining the end point of the window time series
    series_ey <- year(series[n, which(names(series)==x)] %>% pull())
    series_em <- month(series[n, which(names(series)==x)] %>% pull())
  
    ## Creating time series
    df <- tibble(ds=series[m:n, which(names(series)==x)] %>% pull(), 
                 y=series[m:n, which(names(series)==y)] %>% pull())

    ## Building a model with the parameters above using the new training data
    new_model <- prophet(df, seasonality.mode = "multiplicative")
    
    ## Creating forecast frame
    future <- make_future_dataframe(new_model, freq= "month", periods = 1)
    
    ## Creating forecast
    pred <- predict(new_model, future)
    
    ## Filtering the original value
    actual <- series[n+1, which(names(series)==y)] %>% pull()
    
    ## calculating squared errors
    error_sqr <- (pred$yhat[length(pred$yhat)]-actual)^2
    
    ## Updating the errors vector
    errors <- c(errors, error_sqr)
    
    ## Calculating the window size
    windows.size <- c(windows.size, n-m+1)
  }
  
  ## Calculating mean squared errors
  rmse <- (sum(errors)/length(errors))^0.5
  
  return(list("rmse"=rmse, "errors_squared"=errors, "window_size"=windows.size))
  
}

```


### Data Loading

The database used in this study was taken from the open data platform of the ministry of agriculture. The platform has import and export information for various agribusiness products aggregated by month, year, country, state, product, among other groupings. The Information is available at the following link: https://indicadores.agricultura.gov.br/agrostat/index.htm.
As mentioned in the beggining of this study, the dataset will be filtered in order to consider only soy bean volume exported from the Midwest of Brazil.

```{r loading_dataset}
# Reading export dataset
export <- read_csv("export_database.csv")

# Selecting soy bean production in midwest
midwest_soybean <- export %>% 
  filter(produto == 'COMPLEXO SOJA' & regiao == 'CENTRO-OESTE' & ref_ano >= 2000 & ref_ano <= 2021) %>%
  group_by(ref_date_fmd) %>%
  summarize(vl_mm_ton = sum(massa_exportada_kg)/10^9)

```


### Plotting time-series

The following chart shows the mass (millions of ton) of soy bean exported from January of 2000 to December of 2021. In order to account only for complete years, the year of 2022 was left out of this plot, but will be used later on this document.
Looking at the plot, it can be noticed that the time series seems to have a well defined seasonal pattern, but with increasing variance along the years. That is, the series denotes a heteroskedastic behavior. Given this fact, a Box Cox transformation could help make the data more 'normally’ distributed and thus help
stabilize its variance. With this transformation, forecasting can be substantially simpler. For that reason it will also be studied the Box-Cox transformed time series.
 

```{r plotting_series_01, out.width="100%"}
## Plotting
plot <- ggplot() +
  add_serie(data=midwest_soybean %>% mutate(labels = ""), 
            xdata="ref_date_fmd", 
            ydata="vl_mm_ton", 
            name='Soy Bean Export', 
            color="#C4161C", 
            text_position="Above", 
            labels="labels") +
  scale_color_manual(name="", breaks=c('Soy Bean Export'), values=c('#C4161C')) +
  time_series_xlabels() +
  scale_y_continuous(limits=c(0, 9), breaks=seq(0, 9, 1), minor_breaks=seq(0, 9, 0.5)) +
  labs(x = "", 
       y = "Soy Bean Export (MM Ton)",
       title="Soy Bean Export in Midwest of Brazil from Jan-2000 to Dec-2021",
       subtitle="") +
  time_series_theme()

plot
```


### Applying a boxcox transformation on the time-series

A Box-Cox transformation is a power transform function that is used to stabilize variance and make the data more "normally" distributed, which may improve the performance in forecasting for some time-series models. The one-parameter Box-Cox transformation is defined as:   

\begin{align*}
y_{i}^{(\lambda)} = \frac{y_{i}^{(\lambda)}-1}{\lambda} \text{ if } \lambda \ne 0 \\
y_{i}^{(\lambda)} = \ln(y_{i}) \text{ if } \lambda = 0
\end{align*}

Applying the transformation on the original time-series yields:

```{r boxcox, out.width="100%"}
## Calculating boxcox transformation on vl_mm_ton
boxcox_transform <- BoxCox(midwest_soybean$vl_mm_ton, lambda = "auto")

## Creating a new tibble with the transformed vl_mm_ton value
midwest_soybean_boxcox <- tibble(ref_date_fmd = midwest_soybean$ref_date_fmd,
                                 vl_mm_ton_boxcox = c(boxcox_transform))

## Getting calculated lambda
boxcox_lambda <-attributes(boxcox_transform)$lambda

## Plotting
plot <- ggplot() +
  add_serie(data=midwest_soybean_boxcox %>% mutate(labels = ""), 
            xdata="ref_date_fmd", 
            ydata="vl_mm_ton_boxcox", 
            name="Soy Bean Export", 
            color="#C4161C", 
            text_position="Above", 
            labels="labels") +
  scale_color_manual(name="", breaks=c('Soy Bean Export'), values=c('#C4161C')) +
  time_series_xlabels() +
  scale_y_continuous(limits=c(-3, 3), breaks=seq(-3, 3, 1), minor_breaks=seq(-3, 3, 0.5)) +
  labs(x = "", 
       y = "Soy Bean Export (MM Ton)",
       title=paste('Soy Bean Export in Midwest of Brazil | Box-Cox Trans. w/ lambda=', round(boxcox_lambda,2)),
       subtitle="") +
  time_series_theme()

plot
```

It can be seem that the transformation helped to reduce the change in variance over time, although it seems that there is still a difference in the variance of recent years and older years. In order to validate if the transformation in fact helped to give a more normal-like distribution, the following chart shows a qq plot of the original and Box-Cox transformed series. It is evident that the transformed series is more adherent to the straight line in the chart, meaning the transformation has improved normality.  

```{r qqplot, out.width="100%"}
df_hist = rbind(tibble(vl_mm_ton = as.double(midwest_soybean$vl_mm_ton), type = "Original"), 
                tibble(vl_mm_ton = as.double(midwest_soybean_boxcox$vl_mm_ton_boxcox), type = "BoxCox"))
ggplot(df_hist, aes(sample = vl_mm_ton)) +
geom_qq() +
geom_qq_line() +
facet_grid(type ~ ., scales = "free_y") +
ggtitle("QQ plot: Original versus transformed time series", "BoxCox transform improved normality")

```
Plotting the two series side by side it becomes clear that the original series has a trend and increasing volatility, indicating that the series is not stationary. On the other hand, the Box Cox transformation yield a more constant volatility over the entire time period.

```{r comparing_datasets, out.width="100%"}
## Building time series object on exporting data
midwest_soybean_tsibble <- midwest_soybean %>%
    select(ref_date_fmd, vl_mm_ton) %>%
    dplyr::mutate(ref_date_fmd = tsibble::yearmonth(ref_date_fmd)) %>%
    tsibble::as_tsibble(index=ref_date_fmd)

## Original dataset
plot_original <- midwest_soybean_tsibble %>%
  autoplot(vl_mm_ton) +
  geom_smooth() +
  ggtitle("Original scale")

## Building time series object on exporting data
midwest_soybean_boxcox_tsibble <- midwest_soybean_boxcox %>%
    select(ref_date_fmd, vl_mm_ton_boxcox) %>%
    dplyr::mutate(ref_date_fmd = tsibble::yearmonth(ref_date_fmd)) %>%
    tsibble::as_tsibble(index=ref_date_fmd)

## Transformed dataset
plot_boxcox <- midwest_soybean_boxcox_tsibble %>%
  autoplot(vl_mm_ton_boxcox) +
  geom_smooth() +
  ggtitle(paste("Box Cox with lambda = ", round(attributes(boxcox_transform)$lambda,2)))

## Comparision
plot <- ggarrange(plot_original, plot_boxcox, ncol=2, nrow=1, widths=c(1,1), common.legend = FALSE)

annotate_figure(plot, top=text_grob("Soy Bean Export in Midwest of Brazil", 
                                    color="#000000", 
                                    size=14, 
                                    x=unit(0.5, "lines"), 
                                    y=unit(0, "lines"), 
                                    just="left", 
                                    hjust=0, 
                                    vjust=0))

```

### Time Series Analysis and ACF / PACF plots

Analyzing the time series in the above figures it seems that both time series, original and transformed, have a stochastic trend since there seems to be some randomness building up over time. In order to confirm that observation it will be applied a **ADF** (Augmented Dicker-Fuller) test to check if there is unit-roots present in the series.

**ADF test on original time series**
```{r adf_test_original}
tseries::adf.test(midwest_soybean$vl_mm_ton,
                  alternative = c("stationary", "explosive"), 
                  k = trunc((length(midwest_soybean$vl_mm_ton)-1)^(1/3)))
```

**ADF test on transformed time series**
```{r adf_test_transformed}
tseries::adf.test(midwest_soybean_boxcox$vl_mm_ton_boxcox,
                  alternative = c("stationary", "explosive"), 
                  k = trunc((length(midwest_soybean_boxcox$vl_mm_ton_boxcox)-1)^(1/3)))
```

The null hypothesis of the **ADF** assumes that there is an unit root in the time series (therefore the series is non-stationary), whereas the alternate hypothesis, as configured in the function above, assumes that the series are stationary. Since the p-values obtained for both tests are low (less than 0.05) the null hypothesis is rejected indicating that the series, original and transformed, are stationary. However, as mentioned by Robert Hyndman in his book, different unit root tests are available, which are based on different assumptions and may lead to conflicting answers (Hyndman, 2021). In the book, Hyndman suggests the Kwiatkowski-Phillips-Schmidt-Shin (**KPSS**) test (Kwiatkowski et al., 1992) as an alternative. As indicated in the reference mentioned, the **KPSS** test assumes that the data is stationary as the null hypothesis. Therefore, small p-values suggest that the data has an unit root and that differencing is required. In addition, as this analysis deals with a time series of an agricultural crop, it is expected that there is a well-defined seasonality of 12 months. The **fabletools** package also checks for the presence of seasonal unit roots, as it will be studied in the sequence. Applying the **KPSS** looking for seasonal unit roots yields:

**KPSS test on original time series**
```{r seasonal_kpss_test_original}
## Building time series object on exporting data
midwest_soybean_tsibble <- midwest_soybean %>%
    select(ref_date_fmd, vl_mm_ton) %>%
    dplyr::mutate(ref_date_fmd = tsibble::yearmonth(ref_date_fmd)) %>%
    tsibble::as_tsibble(index=ref_date_fmd)

## Performing KPSS test
print(fabletools::features(.tbl=midwest_soybean_tsibble, 
                           .var=vl_mm_ton, 
                           features=list(unitroot_kpss, unitroot_nsdiffs)))

## Performing KPSS test applying one difference with lag 12
print(fabletools::features(.tbl=midwest_soybean_tsibble, 
                           .var=difference(vl_mm_ton, 12), 
                           features=list(unitroot_kpss, unitroot_ndiffs)))
```

**KPSS test on transformed time series**
```{r kpss_test_transformed}
## Building time series object on exporting data
midwest_soybean_boxcox_tsibble <- midwest_soybean_boxcox %>%
    select(ref_date_fmd, vl_mm_ton_boxcox) %>%
    dplyr::mutate(ref_date_fmd = tsibble::yearmonth(ref_date_fmd)) %>%
    tsibble::as_tsibble(index=ref_date_fmd)

## Performing KPSS test
print(fabletools::features(.tbl=midwest_soybean_boxcox_tsibble, 
                           .var=vl_mm_ton_boxcox, 
                           features=list(unitroot_kpss, unitroot_nsdiffs)))

## Performing KPSS test applying one difference with lag 12
print(fabletools::features(.tbl=midwest_soybean_boxcox_tsibble, 
                           .var=difference(vl_mm_ton_boxcox, 12), 
                           features=list(unitroot_kpss, unitroot_ndiffs)))
```

Since the p-value obtained with the **KPSS** test is low for both series (less than 0.05), the null hypothesis is rejected suggesting that both time series are non-stationary, differently from the conclusion obtained with the **ADF** test. Furthermore, the **KPSS** test indicates that one difference is required for each series. It also interesting to notice that applying one difference with a 12 period lag removed the unit root present in the time series, confirming that the stochastic trend is, in fact, related to the 12-months seasonal pattern.

**Differencing the time-series**

```{r}
## Building a time series object on the exporting data with one differencing on exported amount
dt1_midwest_soybean_tsibble <- midwest_soybean %>%
    dplyr::select(ref_date_fmd, vl_mm_ton) %>%
    dplyr::mutate(vl_mm_ton_dt1 = difference(vl_mm_ton, 12)) %>%
    dplyr::select(-vl_mm_ton) %>%
    dplyr::mutate(ref_date_fmd = tsibble::yearmonth(ref_date_fmd)) %>%
    tsibble::as_tsibble(index=ref_date_fmd)

## Building a time series object on the transformed exporting data with one differencing on exported amount
dt1_midwest_soybean_boxcox_tsibble <- midwest_soybean_boxcox %>%
    dplyr::select(ref_date_fmd, vl_mm_ton_boxcox) %>%
    dplyr::mutate(vl_mm_ton_boxcox_dt1 = difference(vl_mm_ton_boxcox, 12)) %>%
    dplyr::select(-vl_mm_ton_boxcox) %>%
    dplyr::mutate(ref_date_fmd = tsibble::yearmonth(ref_date_fmd)) %>%
    tsibble::as_tsibble(index=ref_date_fmd)
```


**Plotting the Auto-Correlation and Partial Auto-Correlation functions**  

```{r acf_pacf_original, out.width="100%"}
## Plotting the auto-correlation function and partial auto-correlation function for the export time series with one difference
dt1_midwest_soybean_tsibble %>%
  gg_tsdisplay(vl_mm_ton_dt1, plot_type='partial')
```

```{r acf_pacf_transformed, out.width="100%"}
## Plotting the auto-correlation function and partial auto-correlation function for the export time series with one difference
dt1_midwest_soybean_boxcox_tsibble %>%
  gg_tsdisplay(vl_mm_ton_boxcox_dt1, plot_type='partial')
```

The **ACF** and **PACF** plots for both series, applied one difference, look similar with some particularities. Looking at the **PACF** plots for the original data, it is noticeable that the remaining series shows an auto-correlation at lag 12 suggesting a **seasonal AR(1)** and a **AR(3)** model due to the high-correlation for lags lower or equal to 3. On the other hand, the **ACF** plot of the original data suggests a **seasonal MA(1)** model due to the high correlation at lag 12 and a **MA(2)** model due to the correlation for lags lower or equal to 2.
Looking now at the transformed time series, the only difference is that the orders of the AR and MA models are **AR(2)** and **MA(4)**, respectively. In summary, the analysis of the **ACF / PACF** plots for both series suggests:

**Original Series**

  - Candidate model 1: ARIMA(3,0,0)(1,1,0)[12] 
  - Candidate model 2: ARIMA(0,0,2)(1,1,0)[12]
  - Candidate model 3: ARIMA(3,0,0)(0,1,1)[12] 
  - Candidate model 4: ARIMA(0,0,2)(0,1,1)[12]

**Transformed Series**

  - Candidate model 1: ARIMA(2,0,0)(1,1,0)[12] 
  - Candidate model 2: ARIMA(0,0,4)(1,1,0)[12]
  - Candidate model 3: ARIMA(2,0,0)(0,1,1)[12] 
  - Candidate model 4: ARIMA(0,0,4)(0,1,1)[12]

This models, along the models suggest by auto-arima algorithms will be verified in upcoming chapters.


## Studying seasonality

Looking at the seasonal plots bellow it becomes clear the seasonal pattern of soy bean export in the Midwest of Brazil: soy bean export are concentrated between March and July, usually peaking between March and May, whereas there is no much export between August and February. That, in fact, makes sense since soy bean is usually harvested between January and May and planted between September and December. Therefore, the peaks of soy bean production would closely related to the harvesting period of the crop.
The seasonal plot bellow shows the seasonal patter for both series, original and transformed, in two different coordinate systems (Cartesian and polar) for better comprehension.

```{r cartesian_seasonal_chart, out.width="100%"}
## Plotting monthly seasonal chart using library feasts | Original | Cartesian view
plot_seasonality_original <- midwest_soybean_tsibble %>% 
  feasts::gg_season(y=vl_mm_ton)

## Plotting monthly seasonal chart using library feasts | Transformed | Cartesian view
plot_seasonality_boxcox <- midwest_soybean_boxcox_tsibble %>% 
  feasts::gg_season(y=vl_mm_ton_boxcox)

## Comparision
plot <- ggarrange(plot_seasonality_original, 
                  plot_seasonality_boxcox, 
                  ncol=2, 
                  nrow=1, 
                  widths=c(1,1),
                  legend="bottom",
                  common.legend = T)

annotate_figure(plot, top=text_grob("Soy Bean Export in Midwest of Brazil", 
                                    color="#000000", 
                                    size=14, 
                                    x=unit(0.5, "lines"), 
                                    y=unit(0, "lines"), 
                                    just="left", 
                                    hjust=0, 
                                    vjust=0))

```


```{r polar_seasonal_chart, out.width="100%"}
## Plotting monthly seasonal chart using library feasts | Original | Polar view
plot_seasonality_original <- midwest_soybean_tsibble %>% 
  feasts::gg_season(y=vl_mm_ton, polar=TRUE)

## Plotting monthly seasonal chart using library feasts | Trasnformed | Polar view
plot_seasonality_boxcox <- midwest_soybean_boxcox_tsibble %>% 
  feasts::gg_season(y=vl_mm_ton_boxcox, polar=TRUE)

## Comparision
plot <- ggarrange(plot_seasonality_original, 
                  plot_seasonality_boxcox, 
                  ncol=2, 
                  nrow=1, 
                  widths=c(1,1),
                  legend="bottom",
                  common.legend = T)

annotate_figure(plot, top=text_grob("Soy Bean Export in Midwest of Brazil", 
                                    color="#000000", 
                                    size=14, 
                                    x=unit(0.5, "lines"), 
                                    y=unit(0, "lines"), 
                                    just="left", 
                                    hjust=0, 
                                    vjust=0))
```

The plots bellow show the decomposition of the time series in its components (trend, seasonal, random), using the **ts** function from base R, considering a multiplicative model. The reason for choosing a multiplicative model at this point was made by intuition since it would be expected that the actual values of soy bean export would the result of some trend multiplied by the percentage of the crop that is export (within a year) each month and that every year, that percentage would be similar. However, the appropriate approach would be to test the two models (additive and multiplicative) and compare the performance.
Comparing the plot for the two time series one thing that comes into attention is that the seasonal and random components are very different. The seasonal component of the transformed series shows a significant peak for July whereas the seasonal component of the original series shows a pattern with values more evenly distributed between months.
For the purpose of this study, only the decomposition function from base R will be studied. However, other decomposition models may give a better result for understanding the components of time series, for example **STL** and **ETS** models.

```{r time_series_decomposition, out.width="100%"}
## Converting the time series into a time series (ts) object 
ts_midwest_soybean <- ts(data=midwest_soybean$vl_mm_ton, # selecting serie
                         start=c(2000, 1), # start month
                         end=c(2021, 12), # end month 
                         frequency=12 # considering monthly frequency
                         )

## Decomposing using base R
plot(decompose(ts_midwest_soybean, "multiplicative"))
```

```{r time_series_boxcox_time_series, out.width="100%"}
## Converting the time series into a time series (ts) object 
ts_midwest_soybean_boxcox <- ts(data=midwest_soybean_boxcox$vl_mm_ton_boxcox, # selecting serie
                                start=c(2000, 1), # start month
                                end=c(2021, 12), # end month 
                                frequency=12 # considering monthly frequency
                                )

## Decomposing using base R
plot(decompose(ts_midwest_soybean_boxcox, "multiplicative"))
```


## Modeling the time series using SARIMA models

In this section it will be evaluated 13 SARIMA models considering both the original time series and the transformed series. Models for similar time series will be compared using the **AIC** (Akaike information criterion) and the best models will them be assessed on its performance later on this study. As mentioned in previous section, the SARIMA model will consider a 12-month seasonality period and it will be used the models suggested from the graphic analysis (identification step of
Box-Jenkins approach) as well as the models chosen by auto-arima from **forecast** package.  

```{r fitting_sarima_models_01}

## Creating a table for holding results
sarima_models <- tibble(model=as.character(), lambda=as.numeric(), aicc=as.numeric())

## Original Series

## Configuring a SARIMA model of orders: ARIMA(3,0,0)(1,1,0)[12]
fit1 <- Arima(y=ts_midwest_soybean,
              order=c(3,0,0),
              seasonal=list(order=c(1,1,0),period=12),
              method="ML")
sarima_models <- bind_rows(sarima_models, tibble(model="SARIMA(3,0,0)(1,1,0)[12]", 
                                                 lambda=NA, 
                                                 aicc=fit1$aicc))

## Configuring a SARIMA model of orders: ARIMA(0,0,2)(1,1,0)[12]
fit2 <- Arima(y=ts_midwest_soybean,
              order=c(0,0,2),
              seasonal=list(order=c(1,1,0),period=12),
              method="ML")
sarima_models <- bind_rows(sarima_models, tibble(model="SARIMA(0,0,2)(1,1,0)[12]", 
                                                 lambda=NA, 
                                                 aicc=fit2$aicc))

## Configuring a SARIMA model of orders: ARIMA(3,0,0)(0,1,1)[12]  
fit3 <- Arima(y=ts_midwest_soybean,
              order=c(3,0,0),
              seasonal=list(order=c(0,1,1),period=12),
              method="ML")
sarima_models <- bind_rows(sarima_models, tibble(model="SARIMA(3,0,0)(0,1,1)[12]", 
                                                 lambda=NA, 
                                                 aicc=fit3$aicc))

## Configuring a SARIMA model of orders: ARIMA(0,0,2)(0,1,1)[12]
fit4 <- Arima(y=ts_midwest_soybean,
              order=c(0,0,2),
              seasonal=list(order=c(0,1,1),period=12),
              method="ML")
sarima_models <- bind_rows(sarima_models, tibble(model="SARIMA(0,0,2)(0,1,1)[12]", 
                                                 lambda=NA, 
                                                 aicc=fit4$aicc))

## Additional model to be tested
## Configuring a SARIMA model of orders: ARIMA(2,0,0)(2,1,2)[12]
fit5 <- Arima(y=ts_midwest_soybean,
              order=c(2,0,0),
              seasonal=list(order=c(2,1,2),period=12),
              method="ML")
sarima_models <- bind_rows(sarima_models, tibble(model="SARIMA(2,0,0)(2,1,2)[12]", 
                                                 lambda=NA, 
                                                 aicc=fit5$aicc))

##Using auto.arima
## Configuring a SARIMA model using auto-arima using setpwise algorithm 
fit6 <- auto.arima(y=ts_midwest_soybean, 
                   stepwise = T)
sarima_models <- bind_rows(sarima_models, tibble(model="Stepwise: SARIMA(0,0,2)(1,1,2)[12]", 
                                                 lambda=NA, 
                                                 aicc=fit6$aicc))

## Configuring a SARIMA model using auto-arima using setpwise algorithm 
fit7 <- auto.arima(y=ts_midwest_soybean, 
                   stepwise = F)
sarima_models <- bind_rows(sarima_models, tibble(model="Search: SARIMA(0,0,2)(1,1,2)[12]", 
                                                 lambda=NA, 
                                                 aicc=fit7$aicc))


## Box-Cox Transformed Series

## Configuring a SARIMA model of orders: ARIMA(2,0,0)(1,1,0)[12]  
fit8 <- Arima(y=ts_midwest_soybean,
              order=c(2,0,0),
              seasonal=list(order=c(1,1,0),period=12),
              method="ML",
              lambda=boxcox_lambda)
sarima_models <- bind_rows(sarima_models, tibble(model="SARIMA(2,0,0)(1,1,0)[12]", 
                                                 lambda=fit8$lambda[1], 
                                                 aicc=fit8$aicc))

## Configuring a SARIMA model of orders: ARIMA(0,0,4)(1,1,0)[12]
fit9 <- Arima(y=ts_midwest_soybean,
              order=c(0,0,4),
              seasonal=list(order=c(1,1,0),period=12),
              method="ML",
              lambda=boxcox_lambda)
sarima_models <- bind_rows(sarima_models, tibble(model="SARIMA(0,0,4)(1,1,0)[12]", 
                                                 lambda=fit9$lambda[1], 
                                                 aicc=fit9$aicc))

## Configuring a SARIMA model of orders: ARIMA(2,0,0)(0,1,1)[12]  
fit10 <- Arima(y=ts_midwest_soybean,
               order=c(2,0,0),
               seasonal=list(order=c(0,1,1),period=12),
               method="ML",
               lambda=boxcox_lambda)
sarima_models <- bind_rows(sarima_models, tibble(model="SARIMA(2,0,0)(0,1,1)[12]", 
                                                 lambda=fit10$lambda[1], 
                                                 aicc=fit10$aicc))

## Configuring a SARIMA model of orders: ARIMA(0,0,4)(0,1,1)[12]
fit11 <- Arima(y=ts_midwest_soybean,
               order=c(0,0,4),
               seasonal=list(order=c(0,1,1),period=12),
               method="ML",
               lambda=boxcox_lambda)
sarima_models <- bind_rows(sarima_models, tibble(model="SARIMA(0,0,4)(0,1,1)[12]", 
                                                 lambda=fit11$lambda[1], 
                                                 aicc=fit11$aicc))

##Using auto.arima
## Configuring a SARIMA model using auto-arima using setpwise algorithm 
fit12 <- auto.arima(y=ts_midwest_soybean, 
                    stepwise = T, 
                    lambda=boxcox_lambda)
sarima_models <- bind_rows(sarima_models, tibble(model="Stepwise: SARIMA(3,0,0)(0,1,1)[12]",
                                                 lambda=fit12$lambda[1], 
                                                 aicc=fit12$aicc))

## Configuring a SARIMA model using auto-arima using setpwise algorithm 
fit13 <- auto.arima(y=ts_midwest_soybean, 
                    stepwise = F, 
                    lambda=boxcox_lambda)
sarima_models <- bind_rows(sarima_models, tibble(model="Search: SARIMA(2,0,0)(2,1,1)[12]",
                                                 lambda=fit13$lambda[1], 
                                                 aicc=fit13$aicc))

sarima_models
```

It can be seen that for both series the **stepwise** algorithm from **auto.arima** does a good job finding the best models due to low **AICc** values. In order to verify if the models mentioned have captured all the information available in the series, a **Ljung-Box** test is performed on the residuals of both models in order to verify if the residuals behave as white noise. If the Ljung-Box test returns a large p-value (we fail to reject the null hypothesis), also suggesting that the residuals are **white noise**. Ljung-Box hypothesis:\

- H0: The residuals **behave like white noise**;
- H1: The residuals **do not behave like white noise**;

The p-values obtained with test are greater than 0.05 for both series meaning that both of the residuals are, in fact, white noise. In other words, the models SARIMA(0,0,2)(1,1,2)[12] and SARIMA(3,0,0)(0,1,1)[12] have captured all the information available in the original and Box-Cox transformed time series, respectively. The **ACF** plot of the residuals indicate that there is no correlation between different lags for the residuals series also indicating that the residuals are white noise.

```{r validating_sarima_original, out.width="100%"}
## Ljung-Box test in the residuals
par(mfrow=c(1,1))
Acf(fit6$residuals, main="ACF of SARIMA(0,0,2)(1,1,2)[12] Residuals | Original Series", xlab="")

## Ljung-Box test in the residuals
print(x=Box.test(fit6$residuals, lag=12, fitdf=1, type="Ljung-Box"))
```

```{r validating_sarima_transformed, out.width="100%"}
## Ljung-Box test in the residuals
par(mfrow=c(1,1))
Acf(fit12$residuals, main="ACF of SARIMA(3,0,0)(0,1,1)[12] Residuals | Transformed Series", xlab="")

## Ljung-Box test in the residuals
print(x=Box.test(fit12$residuals, lag=12, fitdf=1, type="Ljung-Box"))
```

## Plotting the forecast of the time series using the chosen SARIMA model

```{r plotting_orginal_forecast, out.width="100%"}
## Plotting the forecast of the original time series
plot(forecast(fit6,h=12))
```

```{r plotting_transformed_forecast, out.width="100%"}
## Plotting the forecast of the box-cox trnsformed time series
plot(forecast(fit12,h=12))
```

Looking at the predictions plot, it seems that the SARIMA model without box-cox transformation under predicts the last year (2022) since the peak of the series appears considerably lower in 2022 when compared to 2021. On the other hand, although the plot of the serie considering box-cox transformation appears to be more close to what would be expected, it is noticeable that the confidence interval is considerable larger.  

## Forecasting using Prophet

Another package commonly used for forecasting time series is the **Prophet** package developed by Meta (Facebook) team and it is based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality (including holiday effects). In order to compare the performance of the traditional **SARIMA** model with **Prophet**, the soy bean export series without the box-cox transformation will be fit using **Prophet**. 

```{r forecasting_with_prophet, out.width="100%"}
## Renaming columns in order to match prophet's requirements
df = rename(midwest_soybean, ds = ref_date_fmd, y = vl_mm_ton)

## Building a time series object with prophet using a multiplicative seasonality model
m <- prophet(df, seasonality.mode = "multiplicative")

## Creating forecast frame
future <- make_future_dataframe(m, freq= "month", periods = 12)

## Creating forecast
forecast = predict(m, future)

## Plotting forecast
plot(m, forecast)
```

The package also allow the user to plot the seasonal components from the time series, similarly to models based on time series components like **STL** and **ETS**. The components calculated by **Prophet** are shown bellow.

```{r prophet_components, out.width="100%"}
## Plotting time series componentes
prophet_plot_components(m, forecast)
```


It seems that, visually, **Prophet** does a decent job forecasting the next 12 months in the series. However, when calculating the residuals and testing it for white noise, it is noticeable that there are still some correlation left in the residuals (e.g.: lags 1, 2 in the ACF plot) and the p-value obtained with the **Ljung-Box** test is very low, rejecting the null hypothesis which states that the residuals behave like white noise. 
 

```{r acf_prophet, out.width="100%"}
## Calculating the residuals from prophet model
prophet_residuals = df$y - predict(m)$yhat

## Ljung-Box test in the residuals
par(mfrow=c(1,1))
Acf(prophet_residuals, main="ACF of Prophet Residuals | Original Series", xlab="")

## Ljung-Box test in the residuals
print(x=Box.test(prophet_residuals, lag=12, fitdf=1, type="Ljung-Box"))
```


## Backtest

```{r cross_validation}
## Creating a cross validation table
cv_table = tibble(model=as.character(),lambda=as.numeric(), rmse=as.numeric())

## Time Series Cross Validation
rmse_fit6_fw <- tswcv(series=midwest_soybean, 
                      x="ref_date_fmd", 
                      y="vl_mm_ton", 
                      model=fit6, 
                      min.window.size=36, 
                      window.type="fixed")
cv_table <- bind_rows(cv_table, tibble(model="Stepwise: SARIMA(0,0,2)(1,1,2)[12]",
                                       lambda=fit6$lambda[1], 
                                       rmse=rmse_fit6_fw$rmse, 
                                       window_type="fixed"))

rmse_fit6_vw <- tswcv(series=midwest_soybean, 
                      x="ref_date_fmd", 
                      y="vl_mm_ton", 
                      model=fit6, 
                      min.window.size=36, 
                      window.type="variable")
cv_table <- bind_rows(cv_table, tibble(model="Stepwise: SARIMA(0,0,2)(1,1,2)[12]",
                                       lambda=fit6$lambda[1], 
                                       rmse=rmse_fit6_vw$rmse, 
                                       window_type="variable"))

rmse_fit12_fw <- tswcv(series=midwest_soybean, 
                       x="ref_date_fmd", 
                       y="vl_mm_ton", 
                       model=fit12, 
                       min.window.size=36, 
                       window.type="fixed")
cv_table <- bind_rows(cv_table, tibble(model="Stepwise: SARIMA(3,0,0)(0,1,1)[12]",
                                       lambda=fit12$lambda[1], 
                                       rmse=rmse_fit12_fw$rmse, 
                                       window_type="fixed"))

rmse_fit12_vw <- tswcv(series=midwest_soybean, 
                       x="ref_date_fmd", 
                       y="vl_mm_ton", 
                       model=fit12, 
                       min.window.size=36, 
                       window.type="variable")
cv_table <- bind_rows(cv_table, tibble(model="Stepwise: SARIMA(3,0,0)(0,1,1)[12]",
                                       lambda=fit12$lambda[1], 
                                       rmse=rmse_fit12_vw$rmse, 
                                       window_type="variable"))

rmse_prophet_fw <- tswcv_prophet(series=midwest_soybean, 
                                 x="ref_date_fmd", 
                                 y="vl_mm_ton", 
                                 min.window.size=36, 
                                 window.type="fixed")
cv_table <- bind_rows(cv_table, tibble(model="Prophet",
                                       lambda=NULL, 
                                       rmse=rmse_prophet_fw$rmse, 
                                       window_type="fixed"))

rmse_prophet_vw <- tswcv_prophet(series=midwest_soybean, 
                                 x="ref_date_fmd", 
                                 y="vl_mm_ton", 
                                 min.window.size=36, 
                                 window.type="variable")
cv_table <- bind_rows(cv_table, tibble(model="Prophet",
                                       lambda=NULL, 
                                       rmse=rmse_prophet_vw$rmse, 
                                       window_type="variable"))

cv_table
```


Looking at the RMSE values obtained for all models, it is possible to conclude that the SARIMA model without box-cox transformation has the best performance since it has the lowest RMSE value for both cross-validation approaches: fixed window size and variable window size. Therefore, although it seems to be under predicted the values for the year 2022, the back-test shows that this model performs better in general. The second place would be given to the SARIMA model with box-cox transformation, which has the intermediary performance looking at the RMSE values. It is important to highlight, however, that considering only the cross-validation with fixed window, the RMSE of the SARIMA model with box-cox transformation was really close to the model without the transformation. Finally, the last position would be given to the Prophet model since the RMSE obtained with this model was the highest for all cross-validation methods. This outcome is interesting since this model was shown to not have fully captured all the information present in the series since its residuals are not white noise, therefore it would be expected that this model would have the lowest performance. 


### Bibliography

[1] Bodner, C. Box Cox Transformation,  https://harlecin.netlify.app/post/box-cox-and-other-transformations. Acessed on 2022-10-29.

[2] Hyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on 2022-11-01.

[3] Indicadores Agricultura, Ministério da Agrigultura Brasileiro. https://indicadores.agricultura.gov.br/agrostat/index.htm. Acessed on 2022-10-29.
